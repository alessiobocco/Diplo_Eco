{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f978f70f-60dc-4b69-bdb8-9e46aa4cae7e",
      "metadata": {
        "id": "f978f70f-60dc-4b69-bdb8-9e46aa4cae7e"
      },
      "source": [
        "# Modelos de regresión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "30ae4def-5924-44c1-819a-16c12a3521d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30ae4def-5924-44c1-819a-16c12a3521d8",
        "outputId": "1e7da4a3-8610-456b-9f03-fb314d367ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gpboost in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gpboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpboost) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.7/dist-packages (from gpboost) (1.0.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from gpboost) (0.37.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->gpboost) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->gpboost) (1.1.0)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (0.40.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (3.0.6)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (3.0.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.19.5)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.0)\n",
            "Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.20)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (3.2.1)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.19.5)\n",
            "Requirement already satisfied: contextily in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.7/dist-packages (from contextily) (1.2.10)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (from contextily) (1.17.0)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.7/dist-packages (from contextily) (2021.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from contextily) (2.23.0)\n",
            "Requirement already satisfied: mercantile in /usr/local/lib/python3.7/dist-packages (from contextily) (1.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from contextily) (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from contextily) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from contextily) (1.1.0)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy->contextily) (1.52)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->contextily) (1.15.0)\n",
            "Requirement already satisfied: click>=3.0 in /usr/local/lib/python3.7/dist-packages (from mercantile->contextily) (7.1.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (0.7.2)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (2.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (57.4.0)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (1.4.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (2021.10.8)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (21.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->contextily) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->contextily) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->contextily) (3.0.4)\n",
            "Collecting pysal\n",
            "  Downloading pysal-2.5.0.tar.gz (21 kB)\n",
            "Collecting libpysal>=4.5.1\n",
            "  Downloading libpysal-4.5.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 10.2 MB/s \n",
            "\u001b[?25hCollecting access>=1.1.3\n",
            "  Downloading access-1.1.3-py3-none-any.whl (21 kB)\n",
            "Collecting esda>=2.4.1\n",
            "  Downloading esda-2.4.1.tar.gz (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting giddy>=2.3.3\n",
            "  Downloading giddy-2.3.3-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting inequality>=1.0.0\n",
            "  Downloading inequality-1.0.0.tar.gz (11 kB)\n",
            "Collecting pointpats>=2.2.0\n",
            "  Downloading pointpats-2.2.0.tar.gz (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting segregation>=2.0.0\n",
            "  Downloading segregation-2.1.0-py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 45.9 MB/s \n",
            "\u001b[?25hCollecting spaghetti>=1.6.2\n",
            "  Downloading spaghetti-1.6.4-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting mgwr>=2.1.2\n",
            "  Downloading mgwr-2.1.2.tar.gz (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 752 kB/s \n",
            "\u001b[?25hCollecting spglm>=1.0.8\n",
            "  Downloading spglm-1.0.8.tar.gz (37 kB)\n",
            "Collecting spint>=1.0.7\n",
            "  Downloading spint-1.0.7.tar.gz (28 kB)\n",
            "Collecting spreg>=1.2.4\n",
            "  Downloading spreg-1.2.4-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 62.4 MB/s \n",
            "\u001b[?25hCollecting spvcm>=0.3.0\n",
            "  Downloading spvcm-0.3.0.tar.gz (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 1.9 MB/s \n",
            "\u001b[?25hCollecting tobler>=0.8.2\n",
            "  Downloading tobler-0.8.2-py3-none-any.whl (30 kB)\n",
            "Collecting mapclassify>=2.4.3\n",
            "  Downloading mapclassify-2.4.3-py3-none-any.whl (38 kB)\n",
            "Collecting splot>=1.1.4\n",
            "  Downloading splot-1.1.4.tar.gz (34 kB)\n",
            "Collecting spopt>=0.1.2\n",
            "  Downloading spopt-0.2.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.3 MB/s \n",
            "\u001b[?25hCollecting urllib3>=1.26\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 51.8 MB/s \n",
            "\u001b[?25hCollecting python-dateutil<=2.8.0\n",
            "  Downloading python_dateutil-2.8.0-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from pysal) (3.6.4)\n",
            "Collecting pytest-cov\n",
            "  Downloading pytest_cov-3.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: coverage in /usr/local/lib/python3.7/dist-packages (from pysal) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from access>=1.1.3->pysal) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.3 in /usr/local/lib/python3.7/dist-packages (from access>=1.1.3->pysal) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.11 in /usr/local/lib/python3.7/dist-packages (from esda>=2.4.1->pysal) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from esda>=2.4.1->pysal) (1.0.1)\n",
            "Collecting quantecon>=0.4.7\n",
            "  Downloading quantecon-0.5.2-py3-none-any.whl (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from libpysal>=4.5.1->pysal) (4.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from libpysal>=4.5.1->pysal) (2.23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from libpysal>=4.5.1->pysal) (2.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from mapclassify>=2.4.3->pysal) (2.6.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->access>=1.1.3->pysal) (2018.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pointpats>=2.2.0->pysal) (3.2.2)\n",
            "Collecting opencv-contrib-python>=4.2.0\n",
            "  Downloading opencv_contrib_python-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (66.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 66.5 MB 111 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<=2.8.0->pysal) (1.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from quantecon>=0.4.7->giddy>=2.3.3->pysal) (1.7.1)\n",
            "Requirement already satisfied: numba>=0.38 in /usr/local/lib/python3.7/dist-packages (from quantecon>=0.4.7->giddy>=2.3.3->pysal) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.38->quantecon>=0.4.7->giddy>=2.3.3->pysal) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.38->quantecon>=0.4.7->giddy>=2.3.3->pysal) (57.4.0)\n",
            "Collecting pygeos\n",
            "  Downloading pygeos-0.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 71.1 MB/s \n",
            "\u001b[?25hCollecting deprecation\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from segregation>=2.0.0->pysal) (4.62.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from segregation>=2.0.0->pysal) (1.1.0)\n",
            "Requirement already satisfied: geopandas>=0.9 in /usr/local/lib/python3.7/dist-packages (from segregation>=2.0.0->pysal) (0.10.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from segregation>=2.0.0->pysal) (0.11.2)\n",
            "Collecting quilt3\n",
            "  Downloading quilt3-3.6.0-py3-none-any.whl (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 73.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from segregation>=2.0.0->pysal) (21.1.3)\n",
            "Collecting rvlib>=0.0.5\n",
            "  Downloading rvlib-0.0.6.tar.gz (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas>=0.9->segregation>=2.0.0->pysal) (1.8.0)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from geopandas>=0.9->segregation>=2.0.0->pysal) (3.2.1)\n",
            "Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.7/dist-packages (from geopandas>=0.9->segregation>=2.0.0->pysal) (1.8.20)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas>=0.9->segregation>=2.0.0->pysal) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas>=0.9->segregation>=2.0.0->pysal) (0.7.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas>=0.9->segregation>=2.0.0->pysal) (7.1.2)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas>=0.9->segregation>=2.0.0->pysal) (2.5.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas>=0.9->segregation>=2.0.0->pysal) (21.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas>=0.9->segregation>=2.0.0->pysal) (2021.10.8)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from rvlib>=0.0.5->segregation>=2.0.0->pysal) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from rvlib>=0.0.5->segregation>=2.0.0->pysal) (3.13)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->rvlib>=0.0.5->segregation>=2.0.0->pysal) (2.21)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->esda>=2.4.1->pysal) (3.0.0)\n",
            "Collecting rtree\n",
            "  Downloading Rtree-0.9.7-cp37-cp37m-manylinux2010_x86_64.whl (994 kB)\n",
            "\u001b[K     |████████████████████████████████| 994 kB 29.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: descartes in /usr/local/lib/python3.7/dist-packages (from splot>=1.1.4->pysal) (1.1.0)\n",
            "Collecting pulp\n",
            "  Downloading PuLP-2.6.0-py3-none-any.whl (14.2 MB)\n",
            "\u001b[K     |███▊                            | 1.7 MB 1.3 MB/s eta 0:00:10\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 519, in read\n",
            "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 62, in read\n",
            "    data = self.__fp.read(amt)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 465, in read\n",
            "    n = self.readinto(b)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 509, in readinto\n",
            "    n = self.fp.readinto(b)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 589, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 1071, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 929, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 319, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 128, in resolve\n",
            "    requirements, max_rounds=try_to_avoid_resolution_too_deep\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 473, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 367, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 213, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_criteria_to_update(candidate)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 203, in _get_criteria_to_update\n",
            "    name, crit = self._merge_into_criterion(r, parent=candidate)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _merge_into_criterion\n",
            "    if not criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/structs.py\", line 139, in __bool__\n",
            "    return bool(self._sequence)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in __bool__\n",
            "    return any(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 129, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 33, in _iter_built\n",
            "    candidate = func()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 205, in _make_candidate_from_link\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 312, in __init__\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 151, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 234, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 318, in _prepare_distribution\n",
            "    self._ireq, parallel_builds=True\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 508, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 552, in _prepare_linked_requirement\n",
            "    self.download_dir, hashes\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 243, in unpack_url\n",
            "    hashes=hashes,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 102, in get_http_url\n",
            "    from_path, content_type = download(link, temp_dir.path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/network/download.py\", line 157, in __call__\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/progress_bars.py\", line 152, in iter\n",
            "    for x in it:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/network/utils.py\", line 86, in response_chunks\n",
            "    decode_content=False,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 576, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 541, in read\n",
            "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 455, in _error_catcher\n",
            "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
            "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: ConnectionResetError(104, 'Connection reset by peer')\", ConnectionResetError(104, 'Connection reset by peer'))\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install gpboost\n",
        "!pip install shap\n",
        "!pip install xgboost\n",
        "!pip install geopandas\n",
        "!pip install contextily\n",
        "!pip install pysal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7a2892a7-6806-4530-a934-bb6b91c732e1",
      "metadata": {
        "id": "7a2892a7-6806-4530-a934-bb6b91c732e1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import geopandas as gpd\n",
        "from shapely import wkt\n",
        "import contextily\n",
        "\n",
        "# Modelos\n",
        "import gpboost as gpb\n",
        "import shap\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "92b5d2b1-37e0-4dde-83c6-e28204d73454",
      "metadata": {
        "id": "92b5d2b1-37e0-4dde-83c6-e28204d73454"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "526508f6-894a-4aac-9190-69d424be7f15",
      "metadata": {
        "id": "526508f6-894a-4aac-9190-69d424be7f15",
        "tags": []
      },
      "source": [
        "## Lectura de datos "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "acb203ae-c0a4-4bbf-8d91-20eea6b9c64a",
      "metadata": {
        "id": "acb203ae-c0a4-4bbf-8d91-20eea6b9c64a"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/alessiobocco/Diplo_Eco/main/data/modelling_data.csv',  index_col=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9977388e-f263-4780-a71d-e857ecea8880",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "9977388e-f263-4780-a71d-e857ecea8880",
        "outputId": "8569c1db-28b0-4894-f5dd-d339b68a9c9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>antig</th>\n",
              "      <th>m2total</th>\n",
              "      <th>m2cub</th>\n",
              "      <th>ambientes</th>\n",
              "      <th>banios</th>\n",
              "      <th>precioUSD</th>\n",
              "      <th>m2precioUSD</th>\n",
              "      <th>comisaria_dista</th>\n",
              "      <th>obelisco_dista</th>\n",
              "      <th>nrobos</th>\n",
              "      <th>sup_espacio_verde</th>\n",
              "      <th>count_culturales</th>\n",
              "      <th>lon_planar</th>\n",
              "      <th>lat_planar</th>\n",
              "      <th>comunas</th>\n",
              "      <th>barrios</th>\n",
              "      <th>densidad_poblacional</th>\n",
              "      <th>densidad_viviendas</th>\n",
              "      <th>distritos</th>\n",
              "      <th>SobreAvenida</th>\n",
              "      <th>Aestrenar</th>\n",
              "      <th>monoambiente</th>\n",
              "      <th>poi_count_gastronomia</th>\n",
              "      <th>poi_count_educacion</th>\n",
              "      <th>poi_count_roads</th>\n",
              "      <th>poi_count_salud</th>\n",
              "      <th>poi_count_transporte</th>\n",
              "      <th>cardinality</th>\n",
              "      <th>SonCosteros</th>\n",
              "      <th>clusters</th>\n",
              "      <th>zonas_EAH</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1500000</td>\n",
              "      <td>7500.000000</td>\n",
              "      <td>1162.621600</td>\n",
              "      <td>14053.797191</td>\n",
              "      <td>134</td>\n",
              "      <td>68426.445</td>\n",
              "      <td>0</td>\n",
              "      <td>-6.515379e+06</td>\n",
              "      <td>-4.114971e+06</td>\n",
              "      <td>9</td>\n",
              "      <td>LINIERS</td>\n",
              "      <td>9162.535077</td>\n",
              "      <td>3428.444997</td>\n",
              "      <td>NO CARACTERIZADO</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>52.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Sur</td>\n",
              "      <td>POINT (-6515379.180859259 -4114970.853546773)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>43000</td>\n",
              "      <td>2150.000000</td>\n",
              "      <td>832.171100</td>\n",
              "      <td>13886.649121</td>\n",
              "      <td>134</td>\n",
              "      <td>85899.037</td>\n",
              "      <td>0</td>\n",
              "      <td>-6.515279e+06</td>\n",
              "      <td>-4.114576e+06</td>\n",
              "      <td>9</td>\n",
              "      <td>LINIERS</td>\n",
              "      <td>9162.535077</td>\n",
              "      <td>3428.444997</td>\n",
              "      <td>NO CARACTERIZADO</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Sur</td>\n",
              "      <td>POINT (-6515278.659359072 -4114576.319074007)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>97</td>\n",
              "      <td>268</td>\n",
              "      <td>268</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>390000</td>\n",
              "      <td>1455.223881</td>\n",
              "      <td>1711.006598</td>\n",
              "      <td>14133.532780</td>\n",
              "      <td>58</td>\n",
              "      <td>61231.550</td>\n",
              "      <td>0</td>\n",
              "      <td>-6.515252e+06</td>\n",
              "      <td>-4.115700e+06</td>\n",
              "      <td>9</td>\n",
              "      <td>LINIERS</td>\n",
              "      <td>9162.535077</td>\n",
              "      <td>3428.444997</td>\n",
              "      <td>NO CARACTERIZADO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>Sur</td>\n",
              "      <td>POINT (-6515251.60872281 -4115700.427085229)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>270</td>\n",
              "      <td>270</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>390000</td>\n",
              "      <td>1444.000000</td>\n",
              "      <td>1704.004426</td>\n",
              "      <td>14126.937096</td>\n",
              "      <td>59</td>\n",
              "      <td>60861.066</td>\n",
              "      <td>0</td>\n",
              "      <td>-6.515246e+06</td>\n",
              "      <td>-4.115693e+06</td>\n",
              "      <td>9</td>\n",
              "      <td>LINIERS</td>\n",
              "      <td>9162.535077</td>\n",
              "      <td>3428.444997</td>\n",
              "      <td>NO CARACTERIZADO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>Sur</td>\n",
              "      <td>POINT (-6515245.708789796 -4115692.849668185)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>40</td>\n",
              "      <td>268</td>\n",
              "      <td>246</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>360000</td>\n",
              "      <td>1463.000000</td>\n",
              "      <td>1719.768199</td>\n",
              "      <td>14121.499792</td>\n",
              "      <td>55</td>\n",
              "      <td>61723.522</td>\n",
              "      <td>0</td>\n",
              "      <td>-6.515231e+06</td>\n",
              "      <td>-4.115715e+06</td>\n",
              "      <td>9</td>\n",
              "      <td>LINIERS</td>\n",
              "      <td>9162.535077</td>\n",
              "      <td>3428.444997</td>\n",
              "      <td>NO CARACTERIZADO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>Sur</td>\n",
              "      <td>POINT (-6515231.237255995 -4115715.040689695)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  antig  ...  zonas_EAH                                       geometry\n",
              "0   1      0  ...        Sur  POINT (-6515379.180859259 -4114970.853546773)\n",
              "1   6      0  ...        Sur  POINT (-6515278.659359072 -4114576.319074007)\n",
              "2   8     97  ...        Sur   POINT (-6515251.60872281 -4115700.427085229)\n",
              "3   9      1  ...        Sur  POINT (-6515245.708789796 -4115692.849668185)\n",
              "4  10     40  ...        Sur  POINT (-6515231.237255995 -4115715.040689695)\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0954930c-5990-4512-8830-0a46182a5f1f",
      "metadata": {
        "id": "0954930c-5990-4512-8830-0a46182a5f1f"
      },
      "outputs": [],
      "source": [
        "data.loc[:,\"comunas\"] = data.comunas.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5fdee06d-ff58-4911-a160-d49a2f2cbdf0",
      "metadata": {
        "id": "5fdee06d-ff58-4911-a160-d49a2f2cbdf0",
        "outputId": "edb1c513-bc57-4b12-b85a-b7e94b3697e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3670 entries, 0 to 3669\n",
            "Data columns (total 33 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   id                     3670 non-null   int64  \n",
            " 1   antig                  3670 non-null   int64  \n",
            " 2   m2total                3670 non-null   int64  \n",
            " 3   m2cub                  3670 non-null   int64  \n",
            " 4   ambientes              3629 non-null   float64\n",
            " 5   banios                 3670 non-null   int64  \n",
            " 6   precioUSD              3670 non-null   int64  \n",
            " 7   m2precioUSD            3670 non-null   float64\n",
            " 8   comisaria_dista        3670 non-null   float64\n",
            " 9   obelisco_dista         3670 non-null   float64\n",
            " 10  nrobos                 3670 non-null   int64  \n",
            " 11  sup_espacio_verde      3670 non-null   float64\n",
            " 12  count_culturales       3670 non-null   int64  \n",
            " 13  lon_planar             3670 non-null   float64\n",
            " 14  lat_planar             3670 non-null   float64\n",
            " 15  comunas                3670 non-null   object \n",
            " 16  barrios                3670 non-null   object \n",
            " 17  densidad_poblacional   3670 non-null   float64\n",
            " 18  densidad_viviendas     3670 non-null   float64\n",
            " 19  distritos              3670 non-null   object \n",
            " 20  SobreAvenida           3670 non-null   int64  \n",
            " 21  Aestrenar              3670 non-null   int64  \n",
            " 22  monoambiente           3670 non-null   int64  \n",
            " 23  poi_count_gastronomia  3670 non-null   float64\n",
            " 24  poi_count_educacion    3670 non-null   float64\n",
            " 25  poi_count_roads        3670 non-null   float64\n",
            " 26  poi_count_salud        3670 non-null   float64\n",
            " 27  poi_count_transporte   3670 non-null   float64\n",
            " 28  cardinality            3670 non-null   int64  \n",
            " 29  SonCosteros            3670 non-null   float64\n",
            " 30  clusters               3670 non-null   int64  \n",
            " 31  zonas_EAH              3670 non-null   object \n",
            " 32  geometry               3670 non-null   object \n",
            "dtypes: float64(15), int64(13), object(5)\n",
            "memory usage: 974.8+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d1a4e758-0903-48c6-ace1-a807a5c2afbe",
      "metadata": {
        "id": "d1a4e758-0903-48c6-ace1-a807a5c2afbe"
      },
      "outputs": [],
      "source": [
        "data['geometry'] = data['geometry'].apply(wkt.loads)\n",
        "geo_data = gpd.GeoDataFrame(data, crs='epsg:3857').to_crs(epsg=4326)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ea042777-6c35-40d6-9fc2-559792228701",
      "metadata": {
        "id": "ea042777-6c35-40d6-9fc2-559792228701"
      },
      "outputs": [],
      "source": [
        "y = data.precioUSD\n",
        "y_log = np.log(data.precioUSD)\n",
        "X = data.drop([\"precioUSD\", \"id\", \"m2precioUSD\", \"lon_planar\", \"lat_planar\", \"densidad_viviendas\"], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c00510e6-b683-4c09-987d-6a39ddc66403",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "c00510e6-b683-4c09-987d-6a39ddc66403",
        "outputId": "4e40588c-a49e-4750-d14e-aa1c64da6a99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>antig</th>\n",
              "      <th>m2total</th>\n",
              "      <th>m2cub</th>\n",
              "      <th>ambientes</th>\n",
              "      <th>banios</th>\n",
              "      <th>comisaria_dista</th>\n",
              "      <th>obelisco_dista</th>\n",
              "      <th>nrobos</th>\n",
              "      <th>sup_espacio_verde</th>\n",
              "      <th>count_culturales</th>\n",
              "      <th>comunas</th>\n",
              "      <th>barrios</th>\n",
              "      <th>densidad_poblacional</th>\n",
              "      <th>distritos</th>\n",
              "      <th>SobreAvenida</th>\n",
              "      <th>Aestrenar</th>\n",
              "      <th>monoambiente</th>\n",
              "      <th>poi_count_gastronomia</th>\n",
              "      <th>poi_count_educacion</th>\n",
              "      <th>poi_count_roads</th>\n",
              "      <th>poi_count_salud</th>\n",
              "      <th>poi_count_transporte</th>\n",
              "      <th>cardinality</th>\n",
              "      <th>SonCosteros</th>\n",
              "      <th>clusters</th>\n",
              "      <th>zonas_EAH</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1162.621600</td>\n",
              "      <td>14053.797191</td>\n",
              "      <td>134</td>\n",
              "      <td>68426.445</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>LINIERS</td>\n",
              "      <td>9162.535077</td>\n",
              "      <td>NO CARACTERIZADO</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>52.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Sur</td>\n",
              "      <td>POINT (-6515379.181 -4114970.854)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>832.171100</td>\n",
              "      <td>13886.649121</td>\n",
              "      <td>134</td>\n",
              "      <td>85899.037</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>LINIERS</td>\n",
              "      <td>9162.535077</td>\n",
              "      <td>NO CARACTERIZADO</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Sur</td>\n",
              "      <td>POINT (-6515278.659 -4114576.319)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>97</td>\n",
              "      <td>268</td>\n",
              "      <td>268</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1711.006598</td>\n",
              "      <td>14133.532780</td>\n",
              "      <td>58</td>\n",
              "      <td>61231.550</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>LINIERS</td>\n",
              "      <td>9162.535077</td>\n",
              "      <td>NO CARACTERIZADO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>Sur</td>\n",
              "      <td>POINT (-6515251.609 -4115700.427)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>270</td>\n",
              "      <td>270</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1704.004426</td>\n",
              "      <td>14126.937096</td>\n",
              "      <td>59</td>\n",
              "      <td>60861.066</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>LINIERS</td>\n",
              "      <td>9162.535077</td>\n",
              "      <td>NO CARACTERIZADO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>Sur</td>\n",
              "      <td>POINT (-6515245.709 -4115692.850)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40</td>\n",
              "      <td>268</td>\n",
              "      <td>246</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1719.768199</td>\n",
              "      <td>14121.499792</td>\n",
              "      <td>55</td>\n",
              "      <td>61723.522</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>LINIERS</td>\n",
              "      <td>9162.535077</td>\n",
              "      <td>NO CARACTERIZADO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1</td>\n",
              "      <td>Sur</td>\n",
              "      <td>POINT (-6515231.237 -4115715.041)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   antig  m2total  m2cub  ...  clusters  zonas_EAH                           geometry\n",
              "0      0      200    200  ...         0        Sur  POINT (-6515379.181 -4114970.854)\n",
              "1      0       20     20  ...         0        Sur  POINT (-6515278.659 -4114576.319)\n",
              "2     97      268    268  ...        -1        Sur  POINT (-6515251.609 -4115700.427)\n",
              "3      1      270    270  ...        -1        Sur  POINT (-6515245.709 -4115692.850)\n",
              "4     40      268    246  ...        -1        Sur  POINT (-6515231.237 -4115715.041)\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "116fb54c-542f-49d5-967c-cc0e3865070b",
      "metadata": {
        "id": "116fb54c-542f-49d5-967c-cc0e3865070b",
        "outputId": "f26eff22-9fe8-4d56-90df-fae7ec795a8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3670 entries, 0 to 3669\n",
            "Data columns (total 27 columns):\n",
            " #   Column                 Non-Null Count  Dtype   \n",
            "---  ------                 --------------  -----   \n",
            " 0   antig                  3670 non-null   int64   \n",
            " 1   m2total                3670 non-null   int64   \n",
            " 2   m2cub                  3670 non-null   int64   \n",
            " 3   ambientes              3629 non-null   float64 \n",
            " 4   banios                 3670 non-null   int64   \n",
            " 5   comisaria_dista        3670 non-null   float64 \n",
            " 6   obelisco_dista         3670 non-null   float64 \n",
            " 7   nrobos                 3670 non-null   int64   \n",
            " 8   sup_espacio_verde      3670 non-null   float64 \n",
            " 9   count_culturales       3670 non-null   int64   \n",
            " 10  comunas                3670 non-null   object  \n",
            " 11  barrios                3670 non-null   object  \n",
            " 12  densidad_poblacional   3670 non-null   float64 \n",
            " 13  distritos              3670 non-null   object  \n",
            " 14  SobreAvenida           3670 non-null   int64   \n",
            " 15  Aestrenar              3670 non-null   int64   \n",
            " 16  monoambiente           3670 non-null   int64   \n",
            " 17  poi_count_gastronomia  3670 non-null   float64 \n",
            " 18  poi_count_educacion    3670 non-null   float64 \n",
            " 19  poi_count_roads        3670 non-null   float64 \n",
            " 20  poi_count_salud        3670 non-null   float64 \n",
            " 21  poi_count_transporte   3670 non-null   float64 \n",
            " 22  cardinality            3670 non-null   int64   \n",
            " 23  SonCosteros            3670 non-null   float64 \n",
            " 24  clusters               3670 non-null   int64   \n",
            " 25  zonas_EAH              3670 non-null   object  \n",
            " 26  geometry               3670 non-null   geometry\n",
            "dtypes: float64(11), geometry(1), int64(11), object(4)\n",
            "memory usage: 802.8+ KB\n"
          ]
        }
      ],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0514f332-524d-479f-bd62-060dc36207c1",
      "metadata": {
        "id": "0514f332-524d-479f-bd62-060dc36207c1"
      },
      "source": [
        "## Modelo de regresión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "079742fa-5468-4113-bb9c-75e4ba526651",
      "metadata": {
        "id": "079742fa-5468-4113-bb9c-75e4ba526651"
      },
      "outputs": [],
      "source": [
        "variable_names = [\n",
        "    'antig',    \n",
        "    'm2total',   \n",
        "    'm2cub',     \n",
        "    #'ambientes', \n",
        "    'banios',\n",
        "    'comisaria_dista',\n",
        "    'obelisco_dista',\n",
        "    'nrobos',\n",
        "    'sup_espacio_verde',\n",
        "    'count_culturales',\n",
        "    'poi_count_educacion',\n",
        "    'poi_count_roads',\n",
        "    'poi_count_salud',\n",
        "    'poi_count_transporte',\n",
        "    'cardinality',\n",
        "    'clusters',\n",
        "    # Variables binarias\n",
        "    'SobreAvenida',\n",
        "    'Aestrenar',\n",
        "    'monoambiente',\n",
        "    'SonCosteros'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "007a2f3c-ac6d-4ae8-a38c-603feb934a18",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "007a2f3c-ac6d-4ae8-a38c-603feb934a18",
        "outputId": "c714b411-d85a-452e-9e29-788689d8964e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0a55bee5b5c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpysal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspreg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pysal'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from pysal.model import spreg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c60ca573-4fda-47a4-a5c7-9c99a36ac071",
      "metadata": {
        "id": "c60ca573-4fda-47a4-a5c7-9c99a36ac071"
      },
      "source": [
        "X[variable_names]In the context of this chapter, it makes sense to start with `PySAL` as that is the only library that will allow us to move into explicitly spatial econometric models. To fit the model specified in the equation above with $X$ as the list defined, we only need the following line of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98316ad-755d-4067-988e-1cd9f102bae1",
      "metadata": {
        "id": "f98316ad-755d-4067-988e-1cd9f102bae1"
      },
      "outputs": [],
      "source": [
        "# Fit OLS model\n",
        "m1 = spreg.OLS(\n",
        "    # Dependent variable\n",
        "    y_log.values, \n",
        "    # Independent variables\n",
        "    X[variable_names].values,\n",
        "    # Dependent variable name\n",
        "    name_y='log_price', \n",
        "    # Independent variable name\n",
        "    name_x=variable_names\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f00ad1c-61f8-43b7-90b6-205a084ff81a",
      "metadata": {
        "id": "1f00ad1c-61f8-43b7-90b6-205a084ff81a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fabb85b-ee60-48c7-a9a4-483acb0e1103",
      "metadata": {
        "id": "3fabb85b-ee60-48c7-a9a4-483acb0e1103"
      },
      "outputs": [],
      "source": [
        "print(m1.summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f2032d-c51b-497c-ba6f-a4c34199abeb",
      "metadata": {
        "id": "84f2032d-c51b-497c-ba6f-a4c34199abeb"
      },
      "outputs": [],
      "source": [
        "evaluacion_regresion = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b312b2cb-d186-4cd5-b862-9812ff3f3219",
      "metadata": {
        "caption": "Boxplot of prediction errors by neighborhood in San Diego, showing that the basic model systematically over- (or under-) predicts the nightly price of some neighborhoods' Airbnbs.",
        "tags": [],
        "id": "b312b2cb-d186-4cd5-b862-9812ff3f3219"
      },
      "outputs": [],
      "source": [
        "# Create column with residual values from m1\n",
        "evaluacion_regresion['residual'] = m1.u\n",
        "# Obtain the median value of residuals in each neighbourhood\n",
        "medians = evaluacion_regresion.groupby(\n",
        "    \"barrios\"\n",
        ").residual.median().to_frame(\n",
        "    'hood_residual'\n",
        ")\n",
        "\n",
        "# Increase fontsize\n",
        "sns.set(font_scale = 1.25)\n",
        "# Set up figure\n",
        "f = plt.figure(figsize=(15,3))\n",
        "# Grab figure's axis\n",
        "ax = plt.gca()\n",
        "# Generate bloxplot of values by neighbourhood\n",
        "# Note the data includes the median values merged on-the-fly\n",
        "sns.boxplot(\n",
        "    'barrios', \n",
        "    'residual', \n",
        "    ax = ax,\n",
        "    data=evaluacion_regresion.merge(\n",
        "        medians, \n",
        "        how='left',\n",
        "        left_on='barrios',\n",
        "        right_index=True\n",
        "    ).sort_values(\n",
        "        'hood_residual'), palette='bwr'\n",
        ")\n",
        "# Auto-format of the X labels\n",
        "f.autofmt_xdate()\n",
        "# Display\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eba8a278-7104-4171-8cfd-bc94fbd74785",
      "metadata": {
        "id": "eba8a278-7104-4171-8cfd-bc94fbd74785"
      },
      "outputs": [],
      "source": [
        "from pysal.lib import weights\n",
        "from pysal.explore import esda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "056c00f4-6ca3-43af-bd44-c299c0c1b239",
      "metadata": {
        "id": "056c00f4-6ca3-43af-bd44-c299c0c1b239"
      },
      "outputs": [],
      "source": [
        "# Calcular matriz de pesos espaciales\n",
        "w = weights.KNN.from_dataframe(geo_data, k = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21a69f39-0473-46b1-9d01-ae4635ff5371",
      "metadata": {
        "id": "21a69f39-0473-46b1-9d01-ae4635ff5371"
      },
      "source": [
        "This means that, when we compute the *spatial lag* of that $KNN$ weight and the residual, we get the residual of the AirBnB listing closest to each observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "947ec1cb-42fe-4e9f-9127-103361bd5777",
      "metadata": {
        "caption": "The relationship between prediction error for an Airbnb and the nearest Airbnb's prediction error. This suggests that if an Airbnb's nightly price is over-predicted, its nearby Airbnbs will also be over-predicted.",
        "tags": [],
        "id": "947ec1cb-42fe-4e9f-9127-103361bd5777"
      },
      "outputs": [],
      "source": [
        "lag_residual = weights.spatial_lag.lag_spatial(w, m1.u)\n",
        "ax = sns.regplot(\n",
        "    m1.u.flatten(), \n",
        "    lag_residual.flatten(), \n",
        "    line_kws=dict(color='orangered'),\n",
        "    ci=None\n",
        ")\n",
        "ax.set_xlabel('Model Residuals - $u$')\n",
        "ax.set_ylabel('Spatial Lag of Model Residuals - $W u$');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15fb4277-b78e-417d-a99c-216051d9c7e4",
      "metadata": {
        "id": "15fb4277-b78e-417d-a99c-216051d9c7e4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd1fcc2-9839-4ef5-aa99-e6826ffc5752",
      "metadata": {
        "caption": "Map of cluters in regression errors, according to the Local Moran's $I_i$.",
        "tags": [],
        "id": "ebd1fcc2-9839-4ef5-aa99-e6826ffc5752"
      },
      "outputs": [],
      "source": [
        "# Row-standardization\n",
        "w.transform = 'R'\n",
        "# Run LISA on residuals\n",
        "outliers = esda.moran.Moran_Local(m1.u, w, permutations=9999)\n",
        "# Select only LISA cluster cores\n",
        "error_clusters = (outliers.q % 2 == 1)\n",
        "# Filter out non-significant clusters\n",
        "error_clusters &= (outliers.p_sim <= .001)\n",
        "# Add `error_clusters` and `local_I` columns\n",
        "ax = geo_data.assign(\n",
        "    error_clusters = error_clusters,\n",
        "    local_I = outliers.Is\n",
        "# Retain error clusters only\n",
        ").query(\n",
        "    \"error_clusters\"\n",
        "# Sort by I value to largest plot on top\n",
        ").sort_values(\n",
        "    'local_I'\n",
        "# Plot I values\n",
        ").plot(\n",
        "    'local_I', cmap='bwr', marker='.'\n",
        ")\n",
        "# Add basemap\n",
        "contextily.add_basemap(ax, crs=geo_data.crs)\n",
        "# Remove axes\n",
        "ax.set_axis_off();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "668c9a5c-424e-45e3-85c4-29cda94c65d9",
      "metadata": {
        "id": "668c9a5c-424e-45e3-85c4-29cda94c65d9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871ccfef-63e1-4d52-907d-858caa8758fd",
      "metadata": {
        "id": "871ccfef-63e1-4d52-907d-858caa8758fd"
      },
      "outputs": [],
      "source": [
        "# Set up table of regression coefficients\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        # Pull out regression coefficients and\n",
        "        # flatten as they are returned as Nx1 array\n",
        "        'Coeff.': m1.betas.flatten(),\n",
        "        # Pull out and flatten standard errors\n",
        "        'Std. Error': m1.std_err.flatten(),\n",
        "        # Pull out P-values from t-stat object\n",
        "        'P-Value': [i[1] for i in m1.t_stat]\n",
        "    },\n",
        "    index=m1.name_x\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e76d93d1-f831-43de-b9be-640191d34583",
      "metadata": {
        "id": "e76d93d1-f831-43de-b9be-640191d34583"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "503c8c48-f6ca-43b9-8e4c-99256f2a5ee6",
      "metadata": {
        "id": "503c8c48-f6ca-43b9-8e4c-99256f2a5ee6"
      },
      "outputs": [],
      "source": [
        "import statsmodels.formula.api as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50aa067d-e3a1-4ad5-af29-9755fed8b22d",
      "metadata": {
        "id": "50aa067d-e3a1-4ad5-af29-9755fed8b22d"
      },
      "source": [
        "This package provides a formula-like API, which allows us to express the *equation* we wish to estimate directly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f41ce1ca-604c-4a5a-bf58-a151e9b8ea95",
      "metadata": {
        "id": "f41ce1ca-604c-4a5a-bf58-a151e9b8ea95"
      },
      "outputs": [],
      "source": [
        "f = 'precioUSD ~ ' + ' + '.join(variable_names) + ' + comunas - 1'\n",
        "print(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de52ce9d-d2f7-446a-bc36-31b507577528",
      "metadata": {
        "id": "de52ce9d-d2f7-446a-bc36-31b507577528"
      },
      "source": [
        "The *tilde* operator in this statement is usually read as \"log price is a function of ...\", to account for the fact that many different model specifications can be fit according to that functional relationship between `log_price` and our covariate list. Critically, note that the trailing `-1` term means that we are fitting this model without an intercept term. This is necessary, since including an intercept term alongside unique means for every neighborhood would make the underlying system of equations underspecified.  \n",
        "\n",
        "Using this expression, we can estimate the unique effects of each neighborhood, fitting the model in `statsmodels` (note how the specification of the model, formula and data, is separated from the fitting step): "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "875773b6-3f03-4b1b-a863-95f3a502aefb",
      "metadata": {
        "tags": [],
        "id": "875773b6-3f03-4b1b-a863-95f3a502aefb"
      },
      "outputs": [],
      "source": [
        "m2 = sm.ols(f, data=data).fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb6dcb39-91f6-49e2-89df-dca05c0689a6",
      "metadata": {
        "id": "fb6dcb39-91f6-49e2-89df-dca05c0689a6"
      },
      "source": [
        "We could rely on the `summary2()` method to print a similar summary report from the regression but, given it is a lengthy one in this case, we will illustrate how you can extract the spatial fixed effects into a table for display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53f67bbe-0361-456c-be7b-dece8ff553e6",
      "metadata": {
        "id": "53f67bbe-0361-456c-be7b-dece8ff553e6"
      },
      "outputs": [],
      "source": [
        "# Store variable names for all the spatial fixed effects\n",
        "sfe_names = [i for i in m2.params.index if 'comunas' in i]\n",
        "# Create table\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        'Coef.': m2.params[sfe_names],\n",
        "        'Std. Error': m2.bse[sfe_names],\n",
        "        'P-Value': m2.pvalues[sfe_names]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2de8f4fd-5a94-4ba4-ac2d-7dcb38d38cf0",
      "metadata": {
        "id": "2de8f4fd-5a94-4ba4-ac2d-7dcb38d38cf0"
      },
      "outputs": [],
      "source": [
        "m2.params.index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "146f83fd-a086-43c0-a5ca-710f51aa73ba",
      "metadata": {
        "id": "146f83fd-a086-43c0-a5ca-710f51aa73ba"
      },
      "source": [
        "The approach above shows how spatial FE are a particular case of a linear regression with a categorical  variable. Neighborhood membership is modeled using binary dummy variables. Thanks to the formula grammar used in `statsmodels`, we can express the model abstractly, and Python parses it, appropriately creating binary variables as required.\n",
        "\n",
        "The second approach leverages `PySAL` Regimes functionality. We will see regimes below but, for now, think of them as a generalisation of spatial fixed effects where not only $\\alpha$ can vary. This framework allows the user to specify which variables are to be estimated separately for each group. In this case, instead of describing the model in a formula, we need to pass each element of the model as separate arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff2c513-87aa-47b2-aced-1d2be0ac152c",
      "metadata": {
        "id": "7ff2c513-87aa-47b2-aced-1d2be0ac152c"
      },
      "outputs": [],
      "source": [
        "# PySAL spatial fixed effect implementation\n",
        "m3 = spreg.OLS_Regimes(\n",
        "    # Dependent variable\n",
        "    y_log.values, \n",
        "    # Independent variables\n",
        "    X[variable_names].values,\n",
        "    # Variable specifying neighborhood membership\n",
        "    X['comunas'].tolist(),\n",
        "    # Allow the constant term to vary by group/regime\n",
        "    constant_regi='many',\n",
        "    # Variables to be allowed to vary (True) or kept\n",
        "    # constant (False). Here we set all to False\n",
        "    cols2regi=[False]*len(variable_names),\n",
        "    # Allow separate sigma coefficients to be estimated\n",
        "    # by regime (False so a single sigma)\n",
        "    regime_err_sep=False, # Da error. Tengo que averiguar el motivo. Falla el cálculo\n",
        "    # Dependent variable name\n",
        "    name_y='precioUSD', \n",
        "    # Independent variables names\n",
        "    name_x=variable_names\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e52d3515-7425-4e50-b781-c26b5a9ac0a7",
      "metadata": {
        "id": "e52d3515-7425-4e50-b781-c26b5a9ac0a7"
      },
      "source": [
        "Similarly as above, we could rely on the `summary` attribute to print a report with all the results computed. For simplicity here, we will only confirm that, to the 12th decimal, the parameters estimated are indeed the same as those we get from `statsmodels`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d340720-da07-4562-8cd0-7e030431720d",
      "metadata": {
        "id": "4d340720-da07-4562-8cd0-7e030431720d"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "numpy.round(\n",
        "    m3.betas.flatten() - m2.params.values, decimals=12\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b389d95-b951-49ba-84ab-65de39a51c02",
      "metadata": {
        "id": "0b389d95-b951-49ba-84ab-65de39a51c02"
      },
      "source": [
        "Econometrically speaking, what the neighborhood FEs we have introduced imply is that, instead of comparing all house prices across San Diego as equal, we only derive variation from within each postcode. Remember that the interpretation of $\\beta_k$ is the effect of variable $k$, *given all the other explanatory variables included remain constant*. By including a single variable for each area, we are effectively forcing the model to compare as equal only house prices that share the same value for each variable; or, in other words, only houses located within the same area. Introducing FE affords a higher degree of isolation of the effects of the variables we introduce in the model because we can control for unobserved effects that align spatially with the distribution of the FE introduced (by neighborhood, in our case). To make a map of neighborhood fixed effects, we need to process the results from our model slightly.\n",
        "\n",
        "First, we extract only the effects pertaining to the neighborhoods:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "438e6316-3bba-4c4d-95ac-359ae18e4f66",
      "metadata": {
        "id": "438e6316-3bba-4c4d-95ac-359ae18e4f66"
      },
      "outputs": [],
      "source": [
        "neighborhood_effects = m2.params.filter(like='comunas')\n",
        "neighborhood_effects.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0435b18-03b0-4f96-9d91-4701ba2ed319",
      "metadata": {
        "id": "d0435b18-03b0-4f96-9d91-4701ba2ed319"
      },
      "source": [
        "Then, we need to extract just the neighborhood name from the index of this Series. A simple way to do this is to strip all the characters that come before and after our neighborhood names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b8a372-88e1-45b4-af96-369ff6c98faf",
      "metadata": {
        "id": "34b8a372-88e1-45b4-af96-369ff6c98faf"
      },
      "outputs": [],
      "source": [
        "# Create a sequence with the variable names without\n",
        "# `neighborhood[` and `]`\n",
        "stripped = neighborhood_effects.index.str.strip(\n",
        "    'comunas['\n",
        ").str.strip(']')\n",
        "# Reindex the neighborhood_effects Series on clean names\n",
        "neighborhood_effects.index = stripped\n",
        "# Convert Series to DataFrame\n",
        "neighborhood_effects = neighborhood_effects.to_frame('fixed_effect')\n",
        "# Print top of table\n",
        "neighborhood_effects.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98b63528-a079-4930-9183-d377f1580ebb",
      "metadata": {
        "id": "98b63528-a079-4930-9183-d377f1580ebb"
      },
      "source": [
        "Good, we're back to our raw neighborhood names. These allow us to join it to an auxillary file with neighborhood boundaries that is indexed on the same names. Let's read the boundaries first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c76623-8677-4615-9a41-a34e441d0396",
      "metadata": {
        "id": "49c76623-8677-4615-9a41-a34e441d0396"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92a86320-8820-4c05-abd7-94e6709b48be",
      "metadata": {
        "id": "92a86320-8820-4c05-abd7-94e6709b48be"
      },
      "outputs": [],
      "source": [
        "# Descargar geojson de la base de datos del gobierno de CABA\n",
        "url = \"https://cdn.buenosaires.gob.ar/datosabiertos/datasets/barrios/barrios.geojson\"\n",
        "barrios = gpd.read_file(url).to_crs(epsg=3857)\n",
        "# Elegir las columnas de interes\n",
        "barrios = barrios[[\"BARRIO\", \"COMUNA\", \"geometry\"]]\n",
        "# Corregir nombres de variables\n",
        "barrios = barrios.rename(columns = {\"BARRIO\" : \"barrios\", \"COMUNA\" : \"comunas\"})\n",
        "barrios['comunas'] = barrios.comunas.astype(float).astype(int).astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ef17c27-ebb2-4ad7-9b0d-c1de154f9ef5",
      "metadata": {
        "id": "7ef17c27-ebb2-4ad7-9b0d-c1de154f9ef5"
      },
      "source": [
        "And we can then merge the spatial fixed effects and plot them on a map:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9140370-f568-44de-84ab-e06b0181dd72",
      "metadata": {
        "caption": "Neighborhood effects on Airbnb nightly prices. Neighborhoods shown in grey are 'not statistically significant' in their effect on Airbnb prices.",
        "tags": [],
        "id": "e9140370-f568-44de-84ab-e06b0181dd72"
      },
      "outputs": [],
      "source": [
        "# Plot base layer with all neighborhoods in grey\n",
        "ax = barrios.plot(\n",
        "    color='k', linewidth=0, alpha=0.5, figsize=(12,6)\n",
        ")\n",
        "# Merge SFE estimates (note not every polygon\n",
        "# receives an estimate since not every polygon\n",
        "# contains AirBnb properties)\n",
        "barrios.merge(\n",
        "    neighborhood_effects, \n",
        "    how='left',\n",
        "    left_on='comunas', \n",
        "    right_index=True\n",
        "# Drop polygons without a SFE estimate\n",
        ").dropna(\n",
        "    subset=['fixed_effect']\n",
        "# Plot quantile choropleth\n",
        ").plot(\n",
        "    'fixed_effect',     # Variable to display\n",
        "    scheme='quantiles', # Choropleth scheme\n",
        "    k=7,                # No. of classes in the choropleth\n",
        "    linewidth=0.1,      # Polygon border width\n",
        "    cmap='viridis',     # Color scheme\n",
        "    ax=ax               # Axis to draw on\n",
        ")\n",
        "# Add basemap\n",
        "contextily.add_basemap(\n",
        "    ax, \n",
        "    crs=barrios.crs,\n",
        "    source=contextily.providers.CartoDB.PositronNoLabels\n",
        ")\n",
        "# Remove axis\n",
        "ax.set_axis_off()\n",
        "# Display\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1c214d8-d45f-4565-90af-06194b9695ba",
      "metadata": {
        "id": "e1c214d8-d45f-4565-90af-06194b9695ba"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f9cce3e-c31e-4a0c-83e8-13f2cb13d311",
      "metadata": {
        "tags": [],
        "id": "4f9cce3e-c31e-4a0c-83e8-13f2cb13d311"
      },
      "source": [
        "#### Spatial Regimes\n",
        "\n",
        "At the core of estimating spatial FEs is the idea that, instead of assuming the dependent variable behaves uniformly over space, there are systematic effects following a geographical pattern that affect its behavior. In other words, spatial FEs introduce econometrically the notion of spatial heterogeneity. They do this in the simplest possible form: by allowing the constant term to vary geographically. The other elements of the regression are left untouched and hence apply uniformly across space. The idea of spatial regimes (SRs) is to generalize the spatial FE approach to allow not only the constant term to vary but also any other explanatory variable. This implies that the equation we will be estimating is:\n",
        "\n",
        "$$\n",
        "\\log{P_i} = \\alpha_r + \\sum_k \\mathbf{X}_{ki}\\beta_{k-r} + \\epsilon_i\n",
        "$$\n",
        "\n",
        "where we are not only allowing the constant term to vary by region ($\\alpha_r$), but also every other parameter ($\\beta_{k-r}$).\n",
        "\n",
        "To illustrate this approach, we will use the \"spatial differentiator\" of whether a house is in a coastal neighborhood or not (`coastal_neig`) to define the regimes. The rationale behind this choice is that renting a house close to the ocean might be a strong enough pull that people might be willing to pay at different *rates* for each of the house's characteristics.\n",
        "\n",
        "To implement this in Python, we use the `OLS_Regimes` class in `PySAL`, which does most of the heavy lifting for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d09a7c8-c189-41bd-aca3-53937e20bfae",
      "metadata": {
        "id": "0d09a7c8-c189-41bd-aca3-53937e20bfae"
      },
      "outputs": [],
      "source": [
        "X['zonas_EAH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "237c1287-ada8-49e1-b3eb-a094752537db",
      "metadata": {
        "id": "237c1287-ada8-49e1-b3eb-a094752537db"
      },
      "outputs": [],
      "source": [
        "# PySAL spatial regimes implementation\n",
        "m4 = spreg.OLS_Regimes(\n",
        "    # Dependent variable\n",
        "    y.values, \n",
        "    # Independent variables\n",
        "    X[variable_names].values,\n",
        "    # Variable specifying neighborhood membership\n",
        "    X['zonas_EAH'].tolist(),\n",
        "    # Allow the constant term to vary by group/regime\n",
        "    constant_regi='many',\n",
        "    # Allow separate sigma coefficients to be estimated\n",
        "    # by regime (False so a single sigma)\n",
        "    regime_err_sep=False,\n",
        "    # Dependent variable name\n",
        "    name_y='log_price', \n",
        "    # Independent variables names\n",
        "    name_x=variable_names\n",
        "   \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "315004b4-d02c-41a8-a370-ed8cedc5b71d",
      "metadata": {
        "id": "315004b4-d02c-41a8-a370-ed8cedc5b71d"
      },
      "source": [
        "The result can be explored and interpreted similarly to the previous ones. If you inspect the `summary` attribute, you will find the parameters for each variable mostly conform to what you would expect, across both regimes. To compare them, we can plot them side by side on a bespoke table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af0e721f-7f89-45a1-8a7a-841ec41a9c54",
      "metadata": {
        "id": "af0e721f-7f89-45a1-8a7a-841ec41a9c54"
      },
      "outputs": [],
      "source": [
        "# Results table\n",
        "res = pd.DataFrame(\n",
        "    {\n",
        "        # Pull out regression coefficients and\n",
        "        # flatten as they are returned as Nx1 array\n",
        "        'Coeff.': m4.betas.flatten(),\n",
        "        # Pull out and flatten standard errors\n",
        "        'Std. Error': m4.std_err.flatten(),\n",
        "        # Pull out P-values from t-stat object\n",
        "        'P-Value': [i[1] for i in m4.t_stat]\n",
        "    },\n",
        "    index=m4.name_x\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8902cb61-7efb-4bed-b0f0-4f675fd9ad30",
      "metadata": {
        "id": "8902cb61-7efb-4bed-b0f0-4f675fd9ad30"
      },
      "source": [
        "An interesting question arises around the relevance of the regimes. *Are estimates for each variable across regimes statistically different?* For this, the model object also calculates for us what is called a Chow test. This is a statistic that tests the null hypothesis that estimates from different regimes are undistinguishable. If we reject the null, we have evidence suggesting the regimes actually make a difference.\n",
        "\n",
        "Results from the Chow test are available on the `summary` attribute, or we can extract them directly from the model object, which we will do here. There are two types of Chow test. First is a global one that jointly tests for differences between the two regimes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93ee70d0-860f-4c49-aca6-032b3bdd71b0",
      "metadata": {
        "id": "93ee70d0-860f-4c49-aca6-032b3bdd71b0"
      },
      "outputs": [],
      "source": [
        "m5.chow.joint"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "071680f5-e7f2-49a8-8572-17c8b573d8f0",
      "metadata": {
        "id": "071680f5-e7f2-49a8-8572-17c8b573d8f0"
      },
      "source": [
        "The first value represents the statistic, while the second one captures the p-value. In this case, the two regimes are statistically different from each other. The next step then is to check to whether each of the coefficients in our model differ across regimes. For this, we can pull them out into a table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f162ef3b-bc68-4598-8a84-6fd54d0a319e",
      "metadata": {
        "tags": [],
        "id": "f162ef3b-bc68-4598-8a84-6fd54d0a319e"
      },
      "outputs": [],
      "source": [
        "pandas.DataFrame(\n",
        "    # Chow results by variable\n",
        "    m5.chow.regi,\n",
        "    # Name of variables\n",
        "    index=m5.name_x_r,\n",
        "    # Column names\n",
        "    columns=['Statistic', 'P-value']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9633461-1d4f-4e2a-97fb-2d460a3c3570",
      "metadata": {
        "id": "e9633461-1d4f-4e2a-97fb-2d460a3c3570"
      },
      "source": [
        "As we can see in the table, most variables do indeed differ across regimes, statistically speaking. This points to systematic differences in the data generating processes across spatial regimes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e91b63-d55a-40d4-b5ec-eac9f52f96de",
      "metadata": {
        "id": "b3e91b63-d55a-40d4-b5ec-eac9f52f96de"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "01c10f9c-3c44-4a40-a7f9-dad53eb5fa71",
      "metadata": {
        "id": "01c10f9c-3c44-4a40-a7f9-dad53eb5fa71"
      },
      "outputs": [],
      "source": [
        "X = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "53bd128b-55c3-4be9-b3b6-4d6b6137be80",
      "metadata": {
        "id": "53bd128b-55c3-4be9-b3b6-4d6b6137be80"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_min_required_rows(test_size=0.2):\n",
        "    return 1 / test_size\n",
        "\n",
        "def make_stratified_splits(df, y_col=\"label\", test_size=0.2):\n",
        "    \"\"\"\n",
        "        for any class with rows less than min_required_rows corresponding to the input test_size,\n",
        "        all the rows associated with the specific class will have a copy in both the train and test splits.\n",
        "        \n",
        "        example: if test_size is 0.2 (20% otherwise),\n",
        "        min_required_rows = 5 (which is obtained from 1 / test_size i.e., 1 / 0.2)\n",
        "        where the resulting splits will have 4 train rows (80%), 1 test row (20%)..\n",
        "    \"\"\"\n",
        "    \n",
        "    id_col = \"id\"\n",
        "    temp_col = \"same-class-rows\"\n",
        "    \n",
        "    class_to_counts = df[y_col].value_counts()\n",
        "    df[temp_col] = df[y_col].apply(lambda y: class_to_counts[y])\n",
        "    \n",
        "    min_required_rows = get_min_required_rows(test_size)\n",
        "    copy_rows = df[df[temp_col] < min_required_rows].copy(deep=True)\n",
        "    valid_rows = df[df[temp_col] >= min_required_rows].copy(deep=True)\n",
        "    \n",
        "    X = valid_rows[id_col].tolist()\n",
        "    y = valid_rows[y_col].tolist()\n",
        "    \n",
        "    # notice, this train_test_split is a stratified split\n",
        "    X_train, X_test, _, _ = train_test_split(X, y, test_size=test_size, random_state=43, stratify=y)\n",
        "    \n",
        "    X_test = X_test + copy_rows[id_col].tolist()\n",
        "    X_train = X_train + copy_rows[id_col].tolist()\n",
        "    \n",
        "    df.drop([temp_col], axis=1, inplace=True)\n",
        "    \n",
        "    test_df = df[df[id_col].isin(X_test)].copy(deep=True)\n",
        "    train_df = df[df[id_col].isin(X_train)].copy(deep=True)\n",
        "    \n",
        "    print (f\"number of rows in the original dataset: {len(df)}\")\n",
        "    \n",
        "    test_prop = round(len(test_df) / len(df) * 100, 2)\n",
        "    train_prop = round(len(train_df) / len(df) * 100, 2)\n",
        "    print (f\"number of rows in the splits: {len(train_df)} ({train_prop}%), {len(test_df)} ({test_prop}%)\")\n",
        "    \n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ea23f8d5-9fe5-4691-b26c-2a43ab3348c6",
      "metadata": {
        "id": "ea23f8d5-9fe5-4691-b26c-2a43ab3348c6",
        "outputId": "5928b5f4-70c0-4227-becc-9d0c43db8d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of rows in the original dataset: 3670\n",
            "number of rows in the splits: 2936 (80.0%), 734 (20.0%)\n"
          ]
        }
      ],
      "source": [
        "train_data, test_data = make_stratified_splits(data, y_col=\"comunas\", test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "64fce31d-101d-4cfe-9fce-49c1ef194966",
      "metadata": {
        "id": "64fce31d-101d-4cfe-9fce-49c1ef194966"
      },
      "outputs": [],
      "source": [
        "coords_train = train_data[['lon_planar', 'lat_planar']]\n",
        "coords_test = test_data[['lon_planar', 'lat_planar']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "667c6e6c-50d2-4895-b712-3e6ea62add87",
      "metadata": {
        "id": "667c6e6c-50d2-4895-b712-3e6ea62add87"
      },
      "outputs": [],
      "source": [
        "drop_features = ['id', 'lon_planar', 'lat_planar', 'comunas', 'geometry']\n",
        "train_data = train_data.drop(drop_features, axis = 1)\n",
        "test_data = test_data.drop(drop_features, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "f9573f6b-407b-4e3e-b9c1-d8d3dc06de48",
      "metadata": {
        "id": "f9573f6b-407b-4e3e-b9c1-d8d3dc06de48"
      },
      "outputs": [],
      "source": [
        "y_train = train_data.precioUSD\n",
        "y_test = test_data.precioUSD\n",
        "\n",
        "# Eliminar target del dataset\n",
        "X_train = train_data.drop('precioUSD', axis = 1)\n",
        "X_test = test_data.drop('precioUSD', axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "bff23ea0-e413-48a2-bee0-a773e61931df",
      "metadata": {
        "id": "bff23ea0-e413-48a2-bee0-a773e61931df"
      },
      "outputs": [],
      "source": [
        "variables = train_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "c0e7c084-b752-491f-adc1-1b8fa0225950",
      "metadata": {
        "id": "c0e7c084-b752-491f-adc1-1b8fa0225950",
        "outputId": "a27364ac-00c9-4b3b-d506-e75602d334ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['antig', 'm2total', 'm2cub', 'ambientes', 'banios', 'precioUSD',\n",
              "       'm2precioUSD', 'comisaria_dista', 'obelisco_dista', 'nrobos',\n",
              "       'sup_espacio_verde', 'count_culturales', 'barrios',\n",
              "       'densidad_poblacional', 'densidad_viviendas', 'distritos',\n",
              "       'SobreAvenida', 'Aestrenar', 'monoambiente', 'poi_count_gastronomia',\n",
              "       'poi_count_educacion', 'poi_count_roads', 'poi_count_salud',\n",
              "       'poi_count_transporte', 'cardinality', 'SonCosteros', 'clusters',\n",
              "       'zonas_EAH'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "88639faf-3297-4dda-878f-e3f72ed3a170",
      "metadata": {
        "id": "88639faf-3297-4dda-878f-e3f72ed3a170"
      },
      "outputs": [],
      "source": [
        "numerical_variables = ['antig', 'm2total', 'm2cub', 'ambientes', 'banios', \n",
        "                      'comisaria_dista', 'obelisco_dista', 'nrobos', 'sup_espacio_verde',\n",
        "                      'SobreAvenida', 'Aestrenar', 'monoambiente', 'poi_count_gastronomia',\n",
        "                      'poi_count_educacion', 'poi_count_roads', 'poi_count_salud',\n",
        "                      'poi_count_transporte', 'cardinality']\n",
        "\n",
        "categorical_variable = ['SonCosteros', 'clusters', 'distritos', 'SobreAvenida', 'Aestrenar', 'zonas_EAH', 'SonCosteros']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "ea51679a-e3d0-4e93-b3f0-3a091b3ccf92",
      "metadata": {
        "id": "ea51679a-e3d0-4e93-b3f0-3a091b3ccf92"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "num_pipeline = Pipeline([            \n",
        "    ('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    (\"num_cols\", num_pipeline, numerical_variables),\n",
        "    (\"binary_cols\",OneHotEncoder(drop=\"first\"),categorical_variable),\n",
        "])\n",
        "\n",
        "scaler_X = full_pipeline.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "4bc95091-41a8-4fe9-ad68-4955fd6f9845",
      "metadata": {
        "id": "4bc95091-41a8-4fe9-ad68-4955fd6f9845"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "5f734bd7-1cd7-4b2f-8adb-e806ced28fc0",
      "metadata": {
        "id": "5f734bd7-1cd7-4b2f-8adb-e806ced28fc0"
      },
      "outputs": [],
      "source": [
        "#scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "## Aplicamos la transformación de escala sobre los features\n",
        "#scaler_X.fit(X)\n",
        "X_scaled_train = scaler_X.fit_transform(X_train)\n",
        "X_scaled_test  = scaler_X.fit_transform(X_test)\n",
        "\n",
        "## Aplicamos la transformación de escala sobre la variable objetivo\n",
        "## Observación: StandardScaler toma como input una matriz. Si queremos darle un\n",
        "## vector (como por ej. para utilizar con la variable objetivo), tenemos que \n",
        "## transformar ese vector en una matriz de una sola columna. Esto lo hacemos\n",
        "## con el método 'reshape'\n",
        "scaler_y.fit(y_train.values.reshape(-1, 1))\n",
        "y_scaled_train = scaler_y.transform(y_train.values.reshape(-1, 1))[:,0]\n",
        "y_scaled_test  = scaler_y.transform(y_test.values.reshape(-1, 1))[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "e277bce1-ffd5-442e-95b6-59b8f7d343c9",
      "metadata": {
        "id": "e277bce1-ffd5-442e-95b6-59b8f7d343c9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "fec65333-af4f-4791-855b-0a07568ad75d",
      "metadata": {
        "id": "fec65333-af4f-4791-855b-0a07568ad75d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f798198-9be5-470b-a241-c65b9a4d44f8",
      "metadata": {
        "id": "4f798198-9be5-470b-a241-c65b9a4d44f8"
      },
      "outputs": [],
      "source": [
        "gp_model = gpb.GPModel(gp_coords = coords_train, cov_function=\"exponential\")\n",
        "data_train = gpb.Dataset(X_scaled_train, y_train)\n",
        "params = { 'objective': 'regression_l2', 'verbose': 0 }\n",
        "# Training\n",
        "bst = gpb.train(params=params, train_set=data_train,\n",
        "                gp_model=gp_model, num_boost_round=247)\n",
        "gp_model.summary() # Estimated covariance parameters\n",
        "# Prediction\n",
        "pred = bst.predict(data=X_test, gp_coords_pred=coords_test,\n",
        "                    predict_var=True)\n",
        "# Sum the predictions of the trees and the GP\n",
        "y_pred = pred['fixed_effect'] + pred['random_effect_mean']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ff7bcf-a662-42a0-8cec-b9cd74859392",
      "metadata": {
        "id": "c0ff7bcf-a662-42a0-8cec-b9cd74859392"
      },
      "outputs": [],
      "source": [
        "## Utilizaremos la raiz cuadrada del error cuadrático medio como \n",
        "## medida del error\n",
        "def rmse(y1, y2):\n",
        "    \"\"\"\n",
        "    Raiz cuadrada del error cuadrático medio.\n",
        "    \"\"\"\n",
        "    return np.sqrt(mean_squared_error(y1, y2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbc4c08d-ed68-454c-b77c-fbb92e4876e5",
      "metadata": {
        "id": "dbc4c08d-ed68-454c-b77c-fbb92e4876e5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2c74d5-ea04-4217-947e-44a49180221f",
      "metadata": {
        "id": "4d2c74d5-ea04-4217-947e-44a49180221f"
      },
      "outputs": [],
      "source": [
        "## Predicciones sobre conjunto de entrenamiento y validacion\n",
        "pred_test  = scaler_y.inverse_transform(y_pred.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "DA0Yo_gbkNc0",
      "metadata": {
        "id": "DA0Yo_gbkNc0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "041052db-d879-4104-86e2-4542b331160e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "041052db-d879-4104-86e2-4542b331160e",
        "outputId": "71938cd6-a31a-4c6a-e58b-68e00cd4c54d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-b982b1c34723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pred_test' is not defined"
          ]
        }
      ],
      "source": [
        "rmse(y_test, pred_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "32ef6410-c57a-4989-b96e-48900cb357a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "32ef6410-c57a-4989-b96e-48900cb357a9",
        "outputId": "905e3449-eb42-4c04-f86c-07ac7b1d02ad"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-8c1b0a293a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependence_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"m2total\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bst' is not defined"
          ]
        }
      ],
      "source": [
        "shap_values = shap.TreeExplainer(bst).shap_values(X_train)\n",
        "shap.summary_plot(shap_values, X_train)\n",
        "shap.dependence_plot(\"m2total\", shap_values, X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "975fdd85-e73b-4521-b08f-6d6d325301cc",
      "metadata": {
        "id": "975fdd85-e73b-4521-b08f-6d6d325301cc",
        "outputId": "986a3cae-a8f1-49ee-ecdf-6cd5d1c738c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-56-eb1e83f8a981>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    permut = np.random.RandomState(10).choice(a=n, size=n, replace=False)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# --------------------Parameter tuning using a validation set----------------\n",
        "# Define training and validation data by setting indices of 'folds'\n",
        "n = len(X_train_\n",
        "permut = np.random.RandomState(10).choice(a=n, size=n, replace=False)\n",
        "train_idx = permut[0:int(n/2)]\n",
        "valid_idx = permut[int(n/2):n]\n",
        "folds = [(train_idx, valid_idx)]\n",
        "# Parameter tuning using validation data\n",
        "opt_params = gpb.grid_search_tune_parameters(param_grid=param_grid_small,\n",
        "                                             params=params,\n",
        "                                             folds=folds,\n",
        "                                             gp_model=gp_model,\n",
        "                                             use_gp_model_for_validation=True,\n",
        "                                             train_set=data_train,\n",
        "                                             verbose_eval=1,\n",
        "                                             num_boost_round=1000, \n",
        "                                             early_stopping_rounds=10,\n",
        "                                             seed=1000,\n",
        "                                             metrics='binary_logloss')\n",
        "print(\"Best number of iterations: \" + str(opt_params['best_iter']))\n",
        "print(\"Best score: \" + str(opt_params['best_score']))\n",
        "print(\"Best parameters: \" + str(opt_params['best_params']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "ce53b289-fea9-4c13-9311-1b18b672f635",
      "metadata": {
        "id": "ce53b289-fea9-4c13-9311-1b18b672f635"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "d4ba78fb-0c36-402f-af54-0285948ea813",
      "metadata": {
        "id": "d4ba78fb-0c36-402f-af54-0285948ea813"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "528ddcd5-29b0-4ec5-bee0-6d82a0b5a16e",
      "metadata": {
        "id": "528ddcd5-29b0-4ec5-bee0-6d82a0b5a16e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c916e4-08d6-4940-abef-8411831c0958",
      "metadata": {
        "id": "80c916e4-08d6-4940-abef-8411831c0958",
        "outputId": "b66bab1f-ba69-42cd-d3e3-94e413a1a4e7"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "b22bccf3-5c4a-4ac4-9127-b927ecbe9245",
      "metadata": {
        "id": "b22bccf3-5c4a-4ac4-9127-b927ecbe9245"
      },
      "outputs": [],
      "source": [
        "import xgboost as xg\n",
        "from sklearn.metrics import mean_squared_error as MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "33e90066-fe63-4c38-bbb2-409aa9749c06",
      "metadata": {
        "id": "33e90066-fe63-4c38-bbb2-409aa9749c06"
      },
      "outputs": [],
      "source": [
        "# import packages for hyperparameters tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "17e815a2-6074-4167-8412-5af5e008d689",
      "metadata": {
        "id": "17e815a2-6074-4167-8412-5af5e008d689"
      },
      "outputs": [],
      "source": [
        "# Definicion de la funcion de pérdida del RMSE\n",
        "def RMSLE(y, y_pred):\n",
        "    \"\"\" \n",
        "    Función de costo del rmse\n",
        "    \"\"\"\n",
        "    return (np.sqrt(mean_squared_error(y, y_pred)))\n",
        "\n",
        "# Definicion del scoring para usar en la validación\n",
        "rmsle_loss = make_scorer(RMSLE, greater_is_better=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "29e68fb5-cde1-4519-9734-81fa2f570d17",
      "metadata": {
        "id": "29e68fb5-cde1-4519-9734-81fa2f570d17"
      },
      "outputs": [],
      "source": [
        "param_grid={\"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
        "             \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
        "             \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
        "             \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
        "             \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ] }\n",
        "\n",
        "model = xg.XGBRegressor()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "c200d71e-3eaf-4106-9765-b0a1e274ab8a",
      "metadata": {
        "id": "c200d71e-3eaf-4106-9765-b0a1e274ab8a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "3034f47c-0d80-4f97-b6bb-7c104095d3c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3034f47c-0d80-4f97-b6bb-7c104095d3c7",
        "outputId": "c1e43be6-0d13-4303-cd88-47317382dd64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01:59:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            ">RMSE_train=74229.401, RMSE_test=211656.204 score = -0.670, param = {'min_child_weight': 3, 'max_depth': 15, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.4}\n",
            "La iteración tomó 170.973 segundos.\n",
            "[02:02:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            ">RMSE_train=79496.108, RMSE_test=239837.183 score = -0.582, param = {'min_child_weight': 3, 'max_depth': 15, 'learning_rate': 0.05, 'gamma': 0.3, 'colsample_bytree': 0.5}\n",
            "La iteración tomó 171.393 segundos.\n",
            "[02:05:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            ">RMSE_train=58137.517, RMSE_test=227406.749 score = -0.619, param = {'min_child_weight': 1, 'max_depth': 8, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.4}\n",
            "La iteración tomó 180.568 segundos.\n",
            "[02:08:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            ">RMSE_train=64133.444, RMSE_test=288812.100 score = -0.593, param = {'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.25, 'gamma': 0.1, 'colsample_bytree': 0.4}\n",
            "La iteración tomó 184.808 segundos.\n",
            "[02:11:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            ">RMSE_train=50643.037, RMSE_test=332993.289 score = -0.569, param = {'min_child_weight': 3, 'max_depth': 15, 'learning_rate': 0.2, 'gamma': 0.2, 'colsample_bytree': 0.7}\n",
            "La iteración tomó 188.99 segundos.\n",
            "RMSE_train: 65327.902 (10476.148)\n",
            "RMSE_test: 260141.105 (44640.877)\n"
          ]
        }
      ],
      "source": [
        "# Configuración de la validación cruzada anidada\n",
        "cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "# Iterar por las divisiones del dataset original\n",
        "rmse_train_results = list() # Guardar el error de train\n",
        "rmse_test_results = list() # Guardar el error de test\n",
        "best_score = float(\"+inf\") # Indicador para elegir el mejor ajuste\n",
        "\n",
        "for train_ix, test_ix in cv_outer.split(X_scaled_train):\n",
        "    # Comienzo del contador\n",
        "    start = time.time()\n",
        "    # Dividir los datos. El set de train se subdivide en una nueva muestra de train y test\n",
        "    X_train_outer, X_test_outer = X_scaled_train[train_ix, :], X_scaled_train[test_ix, :]\n",
        "    y_train_outer, y_test_outer = y_scaled_train[train_ix], y_scaled_train[test_ix]\n",
        "    \n",
        "    # Configuración de la validacion interna\n",
        "    cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "    # Definir la busqueda\n",
        "    search = RandomizedSearchCV(model, param_grid, scoring=rmsle_loss, cv=cv_inner, n_iter = 100,\n",
        "                                refit=True, verbose = 0, n_jobs = -1)\n",
        "    # Ejecutar busqueda\n",
        "    result = search.fit(X_train_outer, y_train_outer)\n",
        "    # Seleccionar el mejor modelo para esa submuestra\n",
        "    best_model_iteration = result.best_estimator_\n",
        "    # Evaluar el modelo elegido con los datos de test de la submuestra\n",
        "    pred_train = scaler_y.inverse_transform(best_model_iteration.predict(X_train_outer).reshape(-1, 1))\n",
        "    pred_test  = scaler_y.inverse_transform(best_model_iteration.predict(X_test_outer).reshape(-1, 1))\n",
        "    # Convertir la variable objetivo a su escala original\n",
        "    train_rescaled = scaler_y.inverse_transform(y_train_outer.reshape(-1, 1))\n",
        "    test_rescaled  = scaler_y.inverse_transform(y_test_outer.reshape(-1, 1))\n",
        "    # Calcular métricas de error\n",
        "    train_rmse_values = RMSLE(pred_train, train_rescaled)\n",
        "    test_rmse_values = RMSLE(pred_test, test_rescaled)\n",
        "    # Evaluar el modelo. Si la performance en test mejora, se selecciona\n",
        "    if best_score > test_rmse_values:\n",
        "        best_model = result.best_estimator_\n",
        "        best_score = test_rmse_values\n",
        "    # Guardar resultados del error en cada iteración\n",
        "    rmse_train_results.append(train_rmse_values)\n",
        "    rmse_test_results.append(test_rmse_values)\n",
        "    # Reporte de progreso\n",
        "    print('>RMSE_train=%.3f, RMSE_test=%.3f score = %.3f, param = %s' % (train_rmse_values, test_rmse_values, result.best_score_, result.best_params_))\n",
        "    \n",
        "    # Finalizar contador\n",
        "    stop = time.time()\n",
        "    print(\"La iteración tomó\", round(stop-start, 3), \"segundos.\")\n",
        "\n",
        "\n",
        "# Resumen de la perfomance del modelo\n",
        "print('RMSE_train: %.3f (%.3f)' % (np.mean(rmse_train_results), np.std(rmse_train_results)))\n",
        "print('RMSE_test: %.3f (%.3f)' % (np.mean(rmse_test_results), np.std(rmse_test_results)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "1765b4f3-1d9b-40c3-b251-56974037e117",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1765b4f3-1d9b-40c3-b251-56974037e117",
        "outputId": "04da4792-ebbf-4723-c10b-229e5f0fc05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:11:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(colsample_bytree=0.4, gamma=0.2, learning_rate=0.05, max_depth=15,\n",
              "             min_child_weight=3)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# Ajustar el modelo con todos los datos\n",
        "best_model.fit(X_scaled_train, y_scaled_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "ab1c985a-b85a-4fec-9af4-c94947f8d6b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "ab1c985a-b85a-4fec-9af4-c94947f8d6b3",
        "outputId": "cf0694c8-3393-4133-c5a5-9728944d43b5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-6641f8dad4ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Predicciones sobre conjunto de entrenamiento y validacion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train RMSE:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    454\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                                           \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                                           validate_features=validate_features)\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1690\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53']\nexpected f54 in input data"
          ]
        }
      ],
      "source": [
        "## Predicciones sobre conjunto de entrenamiento y validacion\n",
        "pred_train = scaler_y.inverse_transform(best_model.predict(X_scaled_train).reshape(-1, 1))\n",
        "pred_test  = scaler_y.inverse_transform(best_model.predict(X_scaled_test).reshape(-1, 1))\n",
        "\n",
        "print('Train RMSE:', RMSLE(pred_train, y_train))\n",
        "print('Test RMSE:', RMSLE(pred_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "dd258337-58f9-4123-94eb-5fb3594c7d31",
      "metadata": {
        "id": "dd258337-58f9-4123-94eb-5fb3594c7d31"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a64feab-2133-4cef-b676-0ffb5408dd9d",
      "metadata": {
        "id": "8a64feab-2133-4cef-b676-0ffb5408dd9d"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b4bdb9ef-2c00-4865-8e84-c53161e8b1cf",
      "metadata": {
        "id": "b4bdb9ef-2c00-4865-8e84-c53161e8b1cf"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "fbb67579-d54d-4fe4-a987-49d655a80f18",
      "metadata": {
        "id": "fbb67579-d54d-4fe4-a987-49d655a80f18"
      },
      "outputs": [],
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "param_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "model = RandomForestRegressor()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "90bfb3a1-f3a2-4c7e-b740-caaf94c9047c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "90bfb3a1-f3a2-4c7e-b740-caaf94c9047c",
        "outputId": "6532ab81-32af-465e-a681-0d31f65dbc5c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b1493dec409c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"+inf\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Indicador para elegir el mejor ajuste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv_outer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Comienzo del contador\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_scaled_train' is not defined"
          ]
        }
      ],
      "source": [
        "# Configuración de la validación cruzada anidada\n",
        "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "# Iterar por las divisiones del dataset original\n",
        "rmse_train_results = list() # Guardar el error de train\n",
        "rmse_test_results = list() # Guardar el error de test\n",
        "best_score = float(\"+inf\") # Indicador para elegir el mejor ajuste\n",
        "\n",
        "for train_ix, test_ix in cv_outer.split(X_scaled_train):\n",
        "    # Comienzo del contador\n",
        "    start = time.time()\n",
        "    # Dividir los datos. El set de train se subdivide en una nueva muestra de train y test\n",
        "    X_train_outer, X_test_outer = X_scaled_train[train_ix, :], X_scaled_train[test_ix, :]\n",
        "    y_train_outer, y_test_outer = y_scaled_train[train_ix], y_scaled_train[test_ix]\n",
        "    \n",
        "    # Configuración de la validacion interna\n",
        "    cv_inner = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "    # Definir la busqueda\n",
        "    search = RandomizedSearchCV(model, param_grid, scoring=rmsle_loss, cv=cv_inner, n_iter = 100,\n",
        "                                refit=True, verbose = 0, n_jobs = -1)\n",
        "    # Ejecutar busqueda\n",
        "    result = search.fit(X_train_outer, y_train_outer)\n",
        "    # Seleccionar el mejor modelo para esa submuestra\n",
        "    best_model_iteration = result.best_estimator_\n",
        "    # Evaluar el modelo elegido con los datos de test de la submuestra\n",
        "    pred_train = scaler_y.inverse_transform(best_model_iteration.predict(X_train_outer).reshape(-1, 1))\n",
        "    pred_test  = scaler_y.inverse_transform(best_model_iteration.predict(X_test_outer).reshape(-1, 1))\n",
        "    # Convertir la variable objetivo a su escala original\n",
        "    train_rescaled = scaler_y.inverse_transform(y_train_outer.reshape(-1, 1))\n",
        "    test_rescaled  = scaler_y.inverse_transform(y_test_outer.reshape(-1, 1))\n",
        "    # Calcular métricas de error\n",
        "    train_rmse_values = RMSLE(pred_train, train_rescaled)\n",
        "    test_rmse_values = RMSLE(pred_test, test_rescaled)\n",
        "    # Evaluar el modelo. Si la performance en test mejora, se selecciona\n",
        "    if best_score > test_rmse_values:\n",
        "        best_model = result.best_estimator_\n",
        "        best_score = test_rmse_values\n",
        "    # Guardar resultados del error en cada iteración\n",
        "    rmse_train_results.append(train_rmse_values)\n",
        "    rmse_test_results.append(test_rmse_values)\n",
        "    # Reporte de progreso\n",
        "    print('>RMSE_train=%.3f, RMSE_test=%.3f score = %.3f, param = %s' % (train_rmse_values, test_rmse_values, result.best_score_, result.best_params_))\n",
        "    \n",
        "    # Finalizar contador\n",
        "    stop = time.time()\n",
        "    print(\"La iteración tomó\", round(stop-start, 3), \"segundos.\")\n",
        "\n",
        "\n",
        "# Resumen de la perfomance del modelo\n",
        "print('RMSE_train: %.3f (%.3f)' % (np.mean(rmse_train_results), np.std(rmse_train_results)))\n",
        "print('RMSE_test: %.3f (%.3f)' % (np.mean(rmse_test_results), np.std(rmse_test_results)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f4f82e1b-fbed-4244-951e-a45ae9e2af94",
      "metadata": {
        "id": "f4f82e1b-fbed-4244-951e-a45ae9e2af94",
        "outputId": "897fb3f0-2e4a-4a4e-fbb1-ced015d57a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-9e2e29fd88c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ajustar el modelo con todos los datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_scaled_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
          ]
        }
      ],
      "source": [
        "# Ajustar el modelo con todos los datos\n",
        "best_model.fit(X_scaled_train, y_scaled_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "3a86c012-7c33-4c3c-a870-974bdf67c147",
      "metadata": {
        "id": "3a86c012-7c33-4c3c-a870-974bdf67c147",
        "outputId": "db8b561a-7641-40ab-e65f-3f9a422c3f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-6641f8dad4ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Predicciones sobre conjunto de entrenamiento y validacion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train RMSE:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'scaler_y' is not defined"
          ]
        }
      ],
      "source": [
        "## Predicciones sobre conjunto de entrenamiento y validacion\n",
        "pred_train = scaler_y.inverse_transform(best_model.predict(X_scaled_train).reshape(-1, 1))\n",
        "pred_test  = scaler_y.inverse_transform(best_model.predict(X_scaled_test).reshape(-1, 1))\n",
        "\n",
        "print('Train RMSE:', RMSLE(pred_train, y_train))\n",
        "print('Test RMSE:', RMSLE(pred_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c14f656a-ab8f-44dc-9d27-29d6e1b1f4b8",
      "metadata": {
        "id": "c14f656a-ab8f-44dc-9d27-29d6e1b1f4b8"
      },
      "source": [
        "Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "e261bf38-b88a-4ff8-83dc-2877320adfb4",
      "metadata": {
        "id": "e261bf38-b88a-4ff8-83dc-2877320adfb4",
        "outputId": "d949385b-3821-4203-e705-f1861f0e34bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-364503816dda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "train_features = list(X_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38fc32e-82e3-42b9-ac32-5003e94be4c0",
      "metadata": {
        "id": "f38fc32e-82e3-42b9-ac32-5003e94be4c0"
      },
      "outputs": [],
      "source": [
        "base_imp = imp_df(train_features, best_model.feature_importances_)\n",
        "base_imp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31417b21-e41d-43fe-8055-b05d12bd3592",
      "metadata": {
        "id": "31417b21-e41d-43fe-8055-b05d12bd3592"
      },
      "outputs": [],
      "source": [
        "var_imp_plot(base_imp, 'Importancia de cada feature')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fjg-v8V5pb0t"
      },
      "id": "Fjg-v8V5pb0t",
      "execution_count": 36,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Modelo.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}